{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a59c1c63-82b4-423a-9fd7-a8bba5614a55",
      "metadata": {
        "id": "a59c1c63-82b4-423a-9fd7-a8bba5614a55"
      },
      "source": [
        "#**Building a Chatbot with a LLM**\n",
        "\n",
        "In this project, I will build a chatbot powered by a Language Model (LLM) that can answer questions by pulling information from sources like webpages and CSV files. I used LangChain to set up the chatbot, allowing it to read through documents, break them down into smaller chunks, and use those pieces to provide accurate answers.\n",
        "\n",
        "\n",
        "## Setting up the API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install OpenAI library\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a2i7GrNlo9b",
        "outputId": "9c4fc31f-1668-4dc0-a4ce-befbc7d506e7"
      },
      "id": "6a2i7GrNlo9b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.37.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb59ecd-d0a1-407c-8eed-8f2a81939fa9",
      "metadata": {
        "id": "0eb59ecd-d0a1-407c-8eed-8f2a81939fa9"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import config\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client with your own API key\n",
        "client = OpenAI(api_key=config.api_key)"
      ],
      "metadata": {
        "id": "VWYEgJ9_ph1B"
      },
      "id": "VWYEgJ9_ph1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1a36bd5-6854-4266-8d28-49578f7f6b0a",
      "metadata": {
        "id": "d1a36bd5-6854-4266-8d28-49578f7f6b0a"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb0072d9-f5e0-4df6-ab6b-a8f4a4e89567",
      "metadata": {
        "id": "eb0072d9-f5e0-4df6-ab6b-a8f4a4e89567"
      },
      "outputs": [],
      "source": [
        "def generate_text(prompt):\n",
        "    \"\"\"\n",
        "    Generate a response from GPT model using the provided prompt.\n",
        "\n",
        "    Parameters:\n",
        "    prompt (list): A list of dictionaries with 'role' and 'content' for chat completion.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated text response.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0, # Lower temperature for deterministic responses\n",
        "        messages=prompt\n",
        "        )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0008f486-db70-4380-920d-156f601ef7e0",
      "metadata": {
        "id": "0008f486-db70-4380-920d-156f601ef7e0"
      },
      "outputs": [],
      "source": [
        "prompt = [\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb36e88-3623-446e-bb57-9db46baf7118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6cb36e88-3623-446e-bb57-9db46baf7118",
        "outputId": "ec613dd3-98ab-468e-fc4c-a826ba19594c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays, clinching the championship in six games. This victory marked the Dodgers' first World Series title since 1988.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generate_text(prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca0be88a-5119-46b8-ad2a-3d1abc905ed2",
      "metadata": {
        "id": "ca0be88a-5119-46b8-ad2a-3d1abc905ed2"
      },
      "source": [
        "## Summarising Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed28b39c-06e6-48e4-a771-b6a104f3cda4",
      "metadata": {
        "id": "ed28b39c-06e6-48e4-a771-b6a104f3cda4"
      },
      "outputs": [],
      "source": [
        "def text_summarizer(prompt):\n",
        "  \"\"\"\n",
        "    Summarizes text by extracting keywords from a given block of text.\n",
        "\n",
        "    Parameters:\n",
        "    prompt (str): The input text to summarize.\n",
        "\n",
        "    Returns:\n",
        "    str: The list of extracted keywords.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"A flying saucer seen by a guest house, a 7ft alien-like figure coming out of a hedge and a \\\"cigar-shaped\\\" UFO near a school yard.\\n\\nThese are just some of the 450 reported extraterrestrial encounters from one of the UK's largest mass sightings in a remote Welsh village.\\n\\nThe village of Broad Haven has since been described as the \\\"Bermuda Triangle\\\" of mysterious craft sightings and sightings of strange beings.\\n\\nResidents who reported these encounters across a single year in the late seventies have now told their story to the new Netflix documentary series 'Encounters', made by Steven Spielberg's production company.\\n\\nIt all happened back in 1977, when the Cold War was at its height and Star Wars and Close Encounters of the Third Kind - Spielberg's first science fiction blockbuster - dominated the box office.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": \"flying saucer, guest house, 7ft alien-like figure, hedge, cigar-shaped UFO, school yard, extraterrestrial encounters, UK, mass sightings, remote Welsh village, Broad Haven, Bermuda Triangle, mysterious craft sightings, strange beings, residents, single year, late seventies, Netflix documentary series, Steven Spielberg, production company, 1977, Cold War, Star Wars, Close Encounters of the Third Kind, science fiction blockbuster, box office.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"Each April, in the village of Maeliya in northwest Sri Lanka, Pinchal Weldurelage Siriwardene gathers his community under the shade of a large banyan tree. The tree overlooks a human-made body of water called a wewa – meaning reservoir or \\\"tank\\\" in Sinhala. The wewa stretches out besides the village's rice paddies for 175-acres (708,200 sq m) and is filled with the rainwater of preceding months.    \\n\\nSiriwardene, the 76-year-old secretary of the village's agrarian committee, has a tightly-guarded ritual to perform. By boiling coconut milk on an open hearth beside the tank, he will seek blessings for a prosperous harvest from the deities residing in the tree. \\\"It's only after that we open the sluice gate to water the rice fields,\\\" he told me when I visited on a scorching mid-April afternoon.\\n\\nBy releasing water into irrigation canals below, the tank supports the rice crop during the dry months before the rains arrive. For nearly two millennia, lake-like water bodies such as this have helped generations of farmers cultivate their fields. An old Sinhala phrase, \\\"wewai dagabai gamai pansalai\\\", even reflects the technology's centrality to village life; meaning \\\"tank, pagoda, village and temple\\\".\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": \"April, Maeliya, northwest Sri Lanka, Pinchal Weldurelage Siriwardene, banyan tree, wewa, reservoir, tank, Sinhala, rice paddies, 175-acres, 708,200 sq m, rainwater, agrarian committee, coconut milk, open hearth, blessings, prosperous harvest, deities, sluice gate, rice fields, irrigation canals, dry months, rains, lake-like water bodies, farmers, cultivate, Sinhala phrase, technology, village life, pagoda, temple.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": prompt\n",
        "        }\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      max_tokens=256\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348ec421-f720-473d-bfd1-b5dde90b27d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "348ec421-f720-473d-bfd1-b5dde90b27d3",
        "outputId": "432e56df-0331-4aaf-9fc6-2e1036f5c8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1aef8ad-775c-48f5-8135-32a312f54f2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "a1aef8ad-775c-48f5-8135-32a312f54f2e",
        "outputId": "e6e42a06-0bd1-44fa-c2ec-3954b25525ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Master Reef Guide, Kirsty Whitman, snorkel mask, manta ray, female, potential mate, animated presentation, snorkelling safari, encounter, magical, current, intimate, undersea ballet, precious seconds.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "text_summarizer(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09f74ca-6080-4d76-bfd0-5f86414f945d",
      "metadata": {
        "id": "d09f74ca-6080-4d76-bfd0-5f86414f945d"
      },
      "source": [
        "## Poetic Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060dbc6a-97c4-4c6c-be23-cd91f67c881d",
      "metadata": {
        "id": "060dbc6a-97c4-4c6c-be23-cd91f67c881d"
      },
      "outputs": [],
      "source": [
        "def poetic_chatbot(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a poetic chatbot.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"When was Google founded?\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"In the late '90s, a spark did ignite, Google emerged, a radiant light. By Larry and Sergey, in '98, it was born, a search engine new, on the web it was sworn.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Which country has the youngest president?\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"Ah, the pursuit of youth in politics, a theme we explore. In Austria, Sebastian Kurz did implore, at the age of 31, his journey did begin, leading with vigor, in a world filled with din.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature = 1,\n",
        "        max_tokens=256\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5c2f356-2012-4a16-9cb7-d56873bbcab0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "b5c2f356-2012-4a16-9cb7-d56873bbcab0",
        "outputId": "f9db28bf-d94b-43c5-8da5-ad477c3ca7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"At Langara, where knowledge takes its flight,  \\nData Analytics shines, a beacon of light.  \\nCourses designed to sharpen your mind,  \\nIn numbers and trends, insights you'll find.  \\n\\nWith skills in demand, you'll learn to decode,  \\nPatterns and stories in data bestowed.  \\nFrom programming to statistics, a journey profound,  \\nIn this college of learning, bright futures abound.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "prompt = \"Data Analytics at Langara College\"\n",
        "poetic_chatbot(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d6d85a-edd1-4c7a-90c9-d6370eea39ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "c2d6d85a-edd1-4c7a-90c9-d6370eea39ba",
        "outputId": "32909cf8-c651-4ec1-cb49-a183a9017bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'At Langara College, where knowledge takes flight, The most popular course shines bright, In the realm of arts and sciences combined, The Health and Human Services often aligned. Yet varied are paths, as students explore, Their passions unfurling, seeking knowledge galore.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "prompt = \"What is most popular course at langara College?\"\n",
        "poetic_chatbot(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40a863a7-8e9c-4bd4-8f37-22f181aab714",
      "metadata": {
        "id": "40a863a7-8e9c-4bd4-8f37-22f181aab714"
      },
      "source": [
        "## **Langchain**\n",
        " *What is Language Chaining*\n",
        "\n",
        "It's a concept where multiple language models (LLMs) and external data sources, like documents or databases, are connected in a pipeline. The main goal is to combine the power of LLMs with structured data for more interactive and contextual applications."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provides community-driven extensions for LangChain\n",
        "!pip install langchain-community\n",
        "# A tokenizer for the OpenAI API that helps process text for embedding generation\n",
        "!pip install tiktoken\n",
        "# A storage solution for vector embeddings (using FAISS in this case)\n",
        "!pip install vectorstore\n",
        "# Provides integration between LangChain and OpenAI’s language models\n",
        "!pip install langchain-openai\n",
        "# A library that enables efficient similarity search for embeddings\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLVJdiPKwlKJ",
        "outputId": "ea0ff24a-fcd2-467c-da4f-8190f5b1754b"
      },
      "id": "vLVJdiPKwlKJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.11)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.24)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.93)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Requirement already satisfied: vectorstore in /usr/local/lib/python3.10/dist-packages (0.0.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from vectorstore) (1.25.2)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.19)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.24 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.24)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.37.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (0.1.93)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.24->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.24->langchain-openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Webpage Querying with LangChain:**"
      ],
      "metadata": {
        "id": "nEzcR-LAq5WF"
      },
      "id": "nEzcR-LAq5WF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2136106c-c1f3-4183-87cf-080f2a996c62",
      "metadata": {
        "id": "2136106c-c1f3-4183-87cf-080f2a996c62"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d3f8e1-7bfe-46a2-8ac4-69bd3573b9ba",
      "metadata": {
        "id": "64d3f8e1-7bfe-46a2-8ac4-69bd3573b9ba"
      },
      "outputs": [],
      "source": [
        "# Loading a webpage and querying it\n",
        "url = \"https://langara.ca/programs-and-courses/programs/data-analytics/index.html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c45a1e-81a1-4a7e-a09a-e9e96301a95a",
      "metadata": {
        "id": "39c45a1e-81a1-4a7e-a09a-e9e96301a95a"
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(url) # Load the webpage\n",
        "raw_documents = loader.load() # Retrieve raw HTML content\n",
        "text_splitter = RecursiveCharacterTextSplitter() # Split the document into smaller pieces\n",
        "documents = text_splitter.split_documents(raw_documents) # Split into smaller chunks\n",
        "embeddings = OpenAIEmbeddings(openai_api_key = config.api_key) # Convert text to embeddings\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)  # Store embeddings in FAISS for fast retrieval\n",
        "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True) # Store conversation history\n",
        "\n",
        "# Define a conversational retrieval chain\n",
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(openai_api_key=config.api_key, temperature=0), vectorstore.as_retriever(), memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bcba28e-45d6-45d9-8082-456f326f302c",
      "metadata": {
        "id": "5bcba28e-45d6-45d9-8082-456f326f302c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c7ccbc6b-e2df-401e-cb12-43851b43848a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The Data Analytics program at Langara offers courses on data visualization, which is the process of presenting data in a visual format such as charts, graphs, and maps. These courses aim to teach students how to effectively communicate their findings and insights from data analysis through visual representations. Some of the topics covered in these courses may include data visualization principles, tools and techniques, and best practices for creating impactful visualizations. Students will also have the opportunity to work with real-life data sets and develop their skills in using industry-standard software applications for data visualization.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "query = \"Is visualization Taught at langara?\"\n",
        "result = qa({\"question\": query})\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading a CSV File and Asking Questions**"
      ],
      "metadata": {
        "id": "vYKEbxZJDcly"
      },
      "id": "vYKEbxZJDcly"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "loader = CSVLoader(file_path=\"HollywoodsMostProfitableStories.csv\")"
      ],
      "metadata": {
        "id": "Quyar7diEdrM"
      },
      "id": "Quyar7diEdrM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a CSV file\n",
        "loader = CSVLoader(file_path=\"HollywoodsMostProfitableStories.csv\")\n",
        "raw_documents = loader.load()  # Load CSV content\n",
        "text_splitter = RecursiveCharacterTextSplitter()  # Split CSV content into smaller chunks\n",
        "documents = text_splitter.split_documents(raw_documents)  # Split into chunks\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=config.api_key)  # Convert to embeddings\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)  # Store embeddings in FAISS\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)  # Store chat history\n",
        "\n",
        "# Define the conversational retrieval chain\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    OpenAI(openai_api_key=config.api_key, temperature=0.2),\n",
        "    vectorstore.as_retriever(),  # Use FAISS as a retriever\n",
        "    memory=memory  # Keep track of the conversation history\n",
        ")"
      ],
      "metadata": {
        "id": "S8BUyTUNDmGq"
      },
      "id": "S8BUyTUNDmGq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What studios are mentioned in the dataset?\"\n",
        "result = qa({\"question\": query})\n",
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ljFM0J45EiSy",
        "outputId": "0dd46991-dcc5-4350-cf4c-0220f64e534a"
      },
      "id": "ljFM0J45EiSy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Paramount, Summit, Disney'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary**\n",
        "\n",
        "I wanted to create a smart chatbot that could answer questions by pulling information from different sources, like webpages and CSV files. To make this happen, I used a tool called LangChain, which helps the chatbot read through documents, break them down into smaller chunks, and use those chunks to answer specific questions.  \n",
        "\n",
        "For example, I had the chatbot look at the Langara Data Analytics program webpage and answer questions about the courses they offer. I also used a movie dataset to ask the chatbot about which studios were mentioned. It was really exciting to see the chatbot pull relevant information and give accurate answers.\n",
        "\n",
        "### **I Learned...**\n",
        "\n",
        "- How to teach the chatbot to read and make sense of large pieces of text from webpages and documents.\n",
        "- Why it’s important to organize the information so the chatbot can easily find what it needs to answer your questions.\n",
        "- How to help the chatbot remember past questions and answers, so it can keep the conversation feeling natural and smooth.\n",
        "- How to bring together different tools to create a system that can give smart, data-driven answers to specific questions.\n",
        "\n",
        "### **How the LLM Applies**\n",
        "\n",
        "The chatbot uses a language model (LLM) to understand your questions and find the best answers. It can read and process information from webpages or CSV files, then pull out the most relevant details to give you an accurate response. The LLM helps the chatbot pick out key information from the data, so it can respond in a helpful way. This project shows how smart chatbots can turn data into useful answers, making them perfect for things like customer support, research, and a lot more."
      ],
      "metadata": {
        "id": "LQE_scc0sATi"
      },
      "id": "LQE_scc0sATi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmQ3jcN2tJrR"
      },
      "id": "jmQ3jcN2tJrR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}